{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL-E3Lr4F7mi",
        "outputId": "16d8f38d-bba1-4d2f-bb2e-a0bdd3a7b4cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "import tensorflow as tf\n",
        "from keras import regularizers\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras import Input\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "timesteps = 100\n",
        "input_features = 32\n",
        "output_features = 64\n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "state_t = np.zeros((output_features,))\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "successive_outputs = []\n",
        "\n",
        "for input_t in inputs:\n",
        "  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "  successive_outputs.append(output_t)\n",
        "  state_t = output_t\n",
        "\n",
        "final_output_sequence = np.stack(successive_outputs, axis=0)\n",
        "\n",
        "output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "\n",
        "print(output_t)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 14\n",
        "inputs = keras.Input(shape=(None, num_features))\n",
        "outputs = SimpleRNN(16)(inputs)"
      ],
      "metadata": {
        "id": "B6jmLLciJRRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape = (steps, num_features))\n",
        "outputs = SimpleRNN(16, return_sequences = False)(inputs)\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ04UXvxI6GO",
        "outputId": "3e9ff0c0-d176-4cb8-e476-c877b04dca20"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 14\n",
        "steps = 120\n",
        "inputs = keras.Input(shape = (steps, num_features))\n",
        "outputs = SimpleRNN(16, return_sequences = True)(inputs)\n",
        "\n",
        "print(outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUFiF-puI6sm",
        "outputId": "d524f58a-288e-4ceb-9cf0-12fdf8cd0782"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 120, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Inputs(shape = (steps, num_features))\n",
        "x = layers.SimpleRNN(16, return_sequences = True)(inputs)\n",
        "x = layers.SimpleRNN(16, return_sequences = False)(inputs)\n",
        "outputs = layers.SimpleRNN(16)(x)"
      ],
      "metadata": {
        "id": "e4dhogPDJhKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y = activation(dot(state_t, U) + dot(input_t, W) + b)\n",
        "\n",
        "output_t = activation(dot(state_t, Uo) + dot(input_t, Wo) + dot(c_t, Vo) + bo)\n",
        "\n",
        "i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)\n",
        "\n",
        "f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bf)\n",
        "\n",
        "k_t = activation(dot(state_t, Uk) + dot(input_t, Wk) + bk)\n",
        "\n",
        "c_t+1 = i_t * k_t + c_t * f_t\n",
        "\n",
        "Note that this is just pseudo-code for the fundamental operation of an RNN. Even still, the fact that the next layers are technically iterations of the previous layers made much more sense to me. This also explains why the RNN/LSTM part of my Capstone project yielded the best results. "
      ],
      "metadata": {
        "id": "4TyAt2okKjDQ"
      }
    }
  ]
}